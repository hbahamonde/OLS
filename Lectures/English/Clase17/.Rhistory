library(foreign) # significa "foraneo"
load(url("https://github.com/hbahamonde/Metodos_Cuanti_I/raw/master/Lectures/Clase21/data.rdata"))
dat = data_reg
# veamos como se ven los datos (esta es la base de datos de la tarea para la casa # 5)
head(dat)
# estimemos modelo 3 de la tarea # 5
m3 = lm(y3 ~ x3, dat)
# veamos como se ven los problemas de "influence"
library(lattice)
xyplot(m3$residuals ~ dat$x3, type=c("smooth", "p")) # residuos no tienen varianza constante.
# Pero en especial, hay un punto con mucha "influencia"
# Una ruta es la inspeccion visual. Tratemos de hacer algo mas sistematico.
# Calculemos el "Cook's Distance" que es una medida de cuantificar cuanta "influencia"
# tiene cada punto.
options(scipen=100000000) # increases threshold for scientific notation (it's got very small numbers).
m3
cooks.distance(m3)
dat$cooks.d <- cooks.distance(m3)
dat
# grafiquemos los Cooks'D
# install.packages("olsrr")
library(olsrr)
ols_plot_cooksd_chart(m3)
# Ver el error
m3$residuals[6]
# Ver el error
as.vector(m3$residuals)
# Ver el error
dat$residuals = as.vector(m3$residuals)
dat
# El punto de quiebre es 4/n.
4/nrow(dat) # Lo que esta arriba de 0.3636364 (arriba de la linea roja, es influence).
nrow(dat)
4/nrow(dat)
# Estimemos un modelo con leverage
autos <- lm(mpg ~ wt, data = mtcars)
autos
# ahora, grafiquemos lo que vemos vs. lo que predecimos
plot(autos$fitted, mtcars$mpg) # Donde esta el problema?
# Dado que SI tenemos un problema, nuestro error debiera seguir algun patron.
# Es decir, debieramos NO ver una nube dispersa, y la linea debiera ser curva. Veamos.
xyplot(autos$residuals ~ mtcars$wt, type=c("smooth", "d")) # residuos no tienen varianza constante.
# Dado que SI tenemos un problema, nuestro error debiera seguir algun patron.
# Es decir, debieramos NO ver una nube dispersa, y la linea debiera ser curva. Veamos.
xyplot(autos$residuals ~ mtcars$wt, type=c("smooth", "p")) # residuos no tienen varianza constante.
# Ocupemos una funcion de R para detectar observaciones con leverage.
ols_plot_resid_stud_fit(autos) # OK. Son las mismas 3 observaciones que habiamos visto (17, 18 y 20)
rownames(mtcars)
1:nrow(mtcars)
# armemos una base de datos, solo para ver que observaciones/marcas son...
data.frame(
res = model$residuals,
marca = rownames(mtcars),
fila = 1:nrow(mtcars)
)
# armemos una base de datos, solo para ver que observaciones/marcas son...
data.frame(
res = model$residuals,
marca = rownames(mtcars),
fila = 1:nrow(mtcars)
)
# armemos una base de datos, solo para ver que observaciones/marcas son...
data.frame(
res = autos$residuals,
marca = rownames(mtcars),
fila = 1:nrow(mtcars)
)
# Inventemos las variables independientes
set.seed(2020)
rnorm(1000, 10)
mean(rnorm(1000, 10))
x1 = rnorm(1000, 10)
x2 = rnorm(1000, 20)
x3 = (x2*x2)/1000 # x3 es una combinacion linear de x2
x3
mean(x3)
# Definamos que, como debiera ser, el error tiene promedio cero.
e = rnorm(1000, 0)
mean(e)
# modelo verdadero ("true model").
y = b1*x1 + b2*x2 + b3*x3 + e
set.seed(2020)
x1 = rnorm(1000, 10)
x2 = rnorm(1000, 20)
x3 = (x2*x2)/1000 # x3 es una combinacion linear de x2
# Definamos que, como debiera ser, el error tiene promedio cero.
e = rnorm(1000, 0)
# Establecer el valor real de los betas: conocemos con exactitud los valores,
# porque nosotros los creamos!
b1 = 1
b2 = -100
b3 = 500
# modelo verdadero ("true model").
y = b1*x1 + b2*x2 + b3*x3 + e
# Modelo completo
modelo.completo = lm(y ~ x1 + x2 + x3)
summary(modelo.completo)
mean(x1)
# Modelo incompleto
modelo.incompleto = lm(y ~ x1 + x2)
summary(modelo.incompleto)
# Si Variance Inflation Factor (VIF) > 4....multicollinearity
vif(modelo.completo)
?vif
# Si Variance Inflation Factor (VIF) > 4....multicollinearity
vif(modelo.completo)
# Si Variance Inflation Factor (VIF) > 4....multicollinearity
library(car)
vif(modelo.completo)
vif(modelo.incompleto)
cor(x2, x3)
cor(x1, x2)
cor(x2, x2)
lm(y ~ x1 + x2 + x2)
ej.extremo = lm(y ~ x1 + x2 + x2)
summary(ej.extremo)
x2.prima = x2
cor(x2.prima, x2)
ej.extremo.2 = lm(y ~ x1 + x2 + x2.prima)
summary(ej.extremo)
summary(ej.extremo.2)
